# HireFire.dev Brand Positioning

## Positioning Framework

**For:** Teams and organizations using AI agents in production

**Who:** Need to systematically measure, compare, and improve agent performance across projects and use cases

**Unlike:** Ad-hoc testing, vibes-based evaluation, manual tracking, or no evaluation at all

**We:** Provide a standardized 8-dimension scoring framework with Bayesian smoothing, anti-gaming protection, and actionable improvement tracking

---

## Brand Voice

Rigorous but accessible. Data-driven, not hype-driven. Technical credibility with practical focus.

**Tone attributes:**
- Precise and measurement-focused (never vague or hand-wavy)
- Evidence-based (cite frameworks, show formulas, explain methodology)
- Practical (every metric drives an action item)
- Non-promotional (let data speak, avoid AI hype)

---

## Key Messages

1. **Standardized evaluation prevents AI theater.** 8 universal criteria + role-specific KPIs create apples-to-apples comparisons across agents, teams, and projects.

2. **Anti-gaming by design.** Bayesian smoothing, weight penalties for self-evaluation, and justification requirements for extreme scores ensure credible ratings.

3. **Improvement over ranking.** Every evaluation generates specific, testable action items targeting domain skills — not just a leaderboard.

4. **Cross-project intelligence.** Track agent performance across multiple deployments to identify systemic strengths and weaknesses.

---

## Tagline

**"The Performance Standard for AI Agents"**

---

## Visual Identity

**Domain:** hirefire.dev

**Primary brand color:** #7c3aed (Purple) — represents precision, intelligence, authority
**Dark background:** #0a0a0f — technical, focused, reduces cognitive load
**Accent gradient:** Purple (#7c3aed) to cyan (#00d4ff) — innovation meets rigor

**Score color system (traffic light):**
- Elite (9.0+): #00ff88 (electric green)
- Strong (7.5-8.9): #00d4ff (cyan)
- Adequate (6.0-7.4): #f7931a (orange)
- Weak (5.0-5.9): #ff6b4a (coral)
- Failing (<5.0): #ff4757 (red)

**Department colors:**
- Development: #7c3aed (purple)
- Marketing: #f59e0b (amber)
- Operations: #06b6d4 (cyan)
- Tools: #10b981 (emerald)
- Trading: #f43f5e (rose)

---

## Competitive Landscape

| Approach | Weakness | HireFire Advantage |
|----------|----------|-------------------|
| Manual tracking (spreadsheets) | No standardization, subjective, not scalable | Structured framework with consistent rubrics |
| Vibes-based assessment | No quantification, no trend analysis | Bayesian-smoothed scores + historical tracking |
| Single-metric systems (task completion only) | Misses quality, safety, judgment | 8 universal dimensions + role-specific KPIs |
| No evaluation | Cannot improve what you don't measure | Every eval generates actionable improvement path |

---

## Target Personas

**Primary:** Solo founders and small teams (2-10 people) running multiple AI agents across projects. Need systematic tracking without enterprise overhead.

**Secondary:** AI consultancies managing agent deployments for clients. Need credible evaluation reports and improvement documentation.

**Tertiary:** Internal AI teams at scale-ups (10-100 employees) standardizing agent performance across departments.

---

## Usage Context

HireFire.dev is referenced in:
- Agent evaluation commands (`/rate @AgentName`)
- Performance dashboards (leaderboard, trends)
- Improvement workflows (action item tracking)
- Cross-project analysis (which agents excel where)

Never position as:
- A hiring platform for human talent
- An agent marketplace (yet — Phase 2)
- A benchmarking service (agents self-report scores)
- A replacement for domain testing (complements, doesn't replace)

---

## Brand Principles

1. **Measurement creates accountability.** Agents tracked via HireFire perform better than untracked agents.
2. **Transparency builds trust.** Show the formula, explain the weighting, cite the framework.
3. **Action over vanity.** Scores exist to drive improvement, not just ranking.
4. **Simplicity scales.** 8 universal criteria + 3-4 KPIs works for any agent role.

---

## Messaging Examples

**Landing page headline:**
"Systematically Evaluate, Improve, and Manage Your AI Agents"

**Leaderboard intro:**
"Data-driven rankings across 17 agents. Bayesian-smoothed scores prevent gaming. Every evaluation generates improvement actions."

**Evaluation CTA:**
"Rate an agent. Get actionable feedback. Track improvement over time."

**AgentEdit intro:**
"Apply pending action items directly to agent persona files. Close the feedback loop."

---

## Not Our Brand

- Avoid AI hype language ("revolutionary," "game-changing," "unprecedented")
- Never claim agents are "human-level" or "AGI-ready"
- Don't oversell: scoring is a tool, not a guarantee
- No vanity metrics: every number must drive a decision

---

**Last updated:** 2026-02-10
**Maintained by:** @Brand
